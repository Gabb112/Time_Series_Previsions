{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Tuning Notebook ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir(\"/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred\")\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from features.build_features import FeatureEngineering\n",
    "from models.arima import ARIMAModel\n",
    "from models.prophet import ProphetModel\n",
    "from models.lstm import LSTMModel\n",
    "from models.xgboost_model import XGBoostModel\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Directory Setup (adjust as necessary)\n",
    "project_dir = os.getcwd()\n",
    "raw_data_dir = os.path.join(project_dir, \"data\", \"raw\", \"1023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "def load_data(filepath):\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        print(f\"Successfully loaded data from: {filepath}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {filepath}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred loading data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from: /Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/data/raw/1023/sp500_companies.csv\n",
      "Successfully loaded data from: /Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/data/raw/1023/sp500_index.csv\n",
      "Successfully loaded data from: /Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/data/raw/1023/sp500_stocks.csv\n"
     ]
    }
   ],
   "source": [
    "sp500_companies_path = os.path.join(raw_data_dir, \"sp500_companies.csv\")\n",
    "sp500_index_path = os.path.join(raw_data_dir, \"sp500_index.csv\")\n",
    "sp500_stocks_path = os.path.join(raw_data_dir, \"sp500_stocks.csv\")\n",
    "\n",
    "sp500_companies_df = load_data(sp500_companies_path)\n",
    "sp500_index_df = load_data(sp500_index_path)\n",
    "sp500_stocks_df = load_data(sp500_stocks_path)\n",
    "sp500_stocks_df['Date'] = pd.to_datetime(sp500_stocks_df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_stocks_data(sp500_stocks_df):\n",
    "    if sp500_stocks_df is None:\n",
    "        return None\n",
    "    sp500_stocks_df = sp500_stocks_df.dropna(subset=[\"Adj Close\"])\n",
    "    sp500_stocks_df = sp500_stocks_df.sort_values(by=\"Date\").reset_index(drop=True)\n",
    "    return sp500_stocks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_merge_features(sp500_stocks_df, sp500_companies_df):\n",
    "    if sp500_stocks_df is None:\n",
    "        return None\n",
    "    feature_eng = FeatureEngineering()\n",
    "    lags_to_use = [1, 7, 30]\n",
    "    sp500_stocks_df = feature_eng.create_lag_features(\n",
    "        sp500_stocks_df, \"Adj Close\", lags_to_use\n",
    "    )\n",
    "    windows_to_use = [7, 30, 90]\n",
    "    sp500_stocks_df = feature_eng.create_rolling_features(\n",
    "        sp500_stocks_df, \"Adj Close\", windows_to_use\n",
    "    )\n",
    "    sp500_stocks_df = feature_eng.create_calendar_features(sp500_stocks_df, \"Date\")\n",
    "    sp500_stocks_df = feature_eng.merge_company_data(\n",
    "        sp500_stocks_df, sp500_companies_df\n",
    "    )\n",
    "    return sp500_stocks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(sp500_stocks_df):\n",
    "    if sp500_stocks_df is None:\n",
    "        return None, None, None\n",
    "    feature_eng = FeatureEngineering()\n",
    "    train_data, val_data, test_data = feature_eng.time_series_split(\n",
    "        sp500_stocks_df, \"Date\"\n",
    "    )\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged the stock data with company data based on Symbol column.\n",
      "Data has been split in a time-based fashion.\n"
     ]
    }
   ],
   "source": [
    "sp500_stocks_df = preprocess_stocks_data(sp500_stocks_df)\n",
    "sp500_stocks_df = create_and_merge_features(sp500_stocks_df, sp500_companies_df)\n",
    "train_data, val_data, test_data = split_data(sp500_stocks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom RMSE scorer\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ARIMA Hyperparameter Tuning ---\n",
      "ARIMA model has been trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA model has been trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA model has been trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA model has been trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA model has been trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA model has been trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA model has been trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA model has been trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA model has been trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA model has been trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA model has been trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA model has been trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/gagigetsadze/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA model has been trained.\n",
      "Best ARIMA order: (1, 1, 1) and RMSE: nan\n"
     ]
    }
   ],
   "source": [
    "# 1. ARIMA Hyperparameter Tuning\n",
    "if train_data is not None:\n",
    "    print(\"\\n--- ARIMA Hyperparameter Tuning ---\")\n",
    "\n",
    "    class ARIMAGridSearchCVWrapper:\n",
    "        def __init__(self, order):\n",
    "            self.order = order\n",
    "            self.model = ARIMAModel(order=self.order)\n",
    "\n",
    "        def fit(self, X, y=None): # X will be train_data when GridSearchCV uses it\n",
    "                self.model.train(X, target_column=\"Adj Close\")\n",
    "                return self\n",
    "\n",
    "        def predict(self, X):\n",
    "            return self.model.predict(X, target_column = \"Adj Close\")\n",
    "\n",
    "        def get_params(self, deep=True):\n",
    "            return {\"order\" : self.order}\n",
    "\n",
    "        def set_params(self, **params):\n",
    "            self.order = params['order']\n",
    "            self.model = ARIMAModel(order=self.order)\n",
    "            return self\n",
    "\n",
    "    param_grid = {'order': [(p, d, q) for p in range(1, 3) for d in range(1, 2) for q in range(1, 3)]}\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    arima_wrapper = ARIMAGridSearchCVWrapper(order=(5,1,0)) # pass in any order as we will be searching across parameters\n",
    "    grid = GridSearchCV(arima_wrapper, param_grid, cv=tscv, scoring=rmse_scorer, verbose = 0)\n",
    "    grid.fit(train_data)\n",
    "    best_order = grid.best_params_['order']\n",
    "    best_score = -grid.best_score_\n",
    "    print(f\"Best ARIMA order: {best_order} and RMSE: {best_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Prophet Hyperparameter Tuning ---\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'changepoint_prior_scale'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m train_index, val_index \u001b[39min\u001b[39;00m tscv\u001b[39m.\u001b[39msplit(train_data):\n\u001b[1;32m     15\u001b[0m     train, val \u001b[39m=\u001b[39m train_data\u001b[39m.\u001b[39miloc[train_index], train_data\u001b[39m.\u001b[39miloc[val_index]\n\u001b[0;32m---> 16\u001b[0m     model \u001b[39m=\u001b[39m ProphetModel(changepoint_prior_scale\u001b[39m=\u001b[39;49mparam)\n\u001b[1;32m     17\u001b[0m     model\u001b[39m.\u001b[39mtrain(train, target_column\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAdj Close\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m     \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mtrained:\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'changepoint_prior_scale'"
     ]
    }
   ],
   "source": [
    "# 2. Prophet Hyperparameter Tuning\n",
    "if train_data is not None:\n",
    "    print(\"\\n--- Prophet Hyperparameter Tuning ---\")\n",
    "    # We can't do a grid search using prophet directly. Therefore, we will use an example hyperparameter tuning\n",
    "    # process where we tune the changepoint_prior_scale\n",
    "\n",
    "    param_grid = {'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5]}\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "    best_score = float('inf')\n",
    "    best_param = None\n",
    "    for param in param_grid['changepoint_prior_scale']:\n",
    "        scores = []\n",
    "        for train_index, val_index in tscv.split(train_data):\n",
    "            train, val = train_data.iloc[train_index], train_data.iloc[val_index]\n",
    "            model = ProphetModel(changepoint_prior_scale=param)\n",
    "            model.train(train, target_column='Adj Close')\n",
    "            if model.trained:\n",
    "                df_prophet_val = val.rename(columns={'Date': 'ds'})\n",
    "                forecast = model.model.predict(df_prophet_val)\n",
    "                val_predictions = forecast['yhat'].values\n",
    "                score = rmse(val['Adj Close'].values, val_predictions)\n",
    "                scores.append(score)\n",
    "            else:\n",
    "                scores.append(float('inf'))\n",
    "        mean_score = np.mean(scores)\n",
    "        if mean_score < best_score:\n",
    "            best_score = mean_score\n",
    "            best_param = param\n",
    "    print(f\"Best Prophet Parameter:  changepoint_prior_scale = {best_param} and RMSE: {best_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LSTM Hyperparameter Tuning ---\n",
      "Epoch: 1/50, Training Loss:0.0881, Validation Loss: 0.0259\n",
      "Epoch: 2/50, Training Loss:0.0845, Validation Loss: 0.0245\n",
      "Epoch: 3/50, Training Loss:0.0900, Validation Loss: 0.0268\n",
      "Epoch: 4/50, Training Loss:0.0917, Validation Loss: 0.0275\n",
      "Epoch: 5/50, Training Loss:0.0881, Validation Loss: 0.0260\n",
      "Epoch: 6/50, Training Loss:0.0876, Validation Loss: 0.0258\n",
      "Epoch: 7/50, Training Loss:0.0873, Validation Loss: 0.0256\n",
      "Epoch: 8/50, Training Loss:0.0855, Validation Loss: 0.0249\n",
      "Epoch: 9/50, Training Loss:0.0923, Validation Loss: 0.0278\n",
      "Epoch: 10/50, Training Loss:0.0865, Validation Loss: 0.0250\n",
      "Epoch: 11/50, Training Loss:0.0884, Validation Loss: 0.0260\n",
      "Epoch: 12/50, Training Loss:0.0879, Validation Loss: 0.0257\n",
      "Epoch: 13/50, Training Loss:0.0892, Validation Loss: 0.0264\n",
      "Epoch: 14/50, Training Loss:0.0889, Validation Loss: 0.0262\n",
      "Epoch: 15/50, Training Loss:0.0877, Validation Loss: 0.0258\n",
      "Epoch: 16/50, Training Loss:0.0874, Validation Loss: 0.0257\n",
      "Epoch: 17/50, Training Loss:0.0900, Validation Loss: 0.0265\n",
      "Epoch: 18/50, Training Loss:0.0895, Validation Loss: 0.0264\n",
      "Epoch: 19/50, Training Loss:0.0903, Validation Loss: 0.0267\n",
      "Epoch: 20/50, Training Loss:0.0893, Validation Loss: 0.0263\n",
      "Epoch: 21/50, Training Loss:0.0893, Validation Loss: 0.0264\n",
      "Epoch: 22/50, Training Loss:0.0894, Validation Loss: 0.0261\n",
      "Epoch: 23/50, Training Loss:0.0887, Validation Loss: 0.0261\n",
      "Epoch: 24/50, Training Loss:0.0886, Validation Loss: 0.0259\n",
      "Epoch: 25/50, Training Loss:0.0885, Validation Loss: 0.0259\n",
      "Epoch: 26/50, Training Loss:0.0875, Validation Loss: 0.0254\n",
      "Epoch: 27/50, Training Loss:0.0912, Validation Loss: 0.0268\n",
      "Epoch: 28/50, Training Loss:0.0887, Validation Loss: 0.0260\n",
      "Epoch: 29/50, Training Loss:0.0906, Validation Loss: 0.0268\n",
      "Epoch: 30/50, Training Loss:0.0929, Validation Loss: 0.0273\n",
      "Epoch: 31/50, Training Loss:0.0910, Validation Loss: 0.0268\n",
      "Epoch: 32/50, Training Loss:0.0882, Validation Loss: 0.0259\n",
      "Epoch: 33/50, Training Loss:0.0910, Validation Loss: 0.0267\n",
      "Epoch: 34/50, Training Loss:0.0902, Validation Loss: 0.0262\n",
      "Epoch: 35/50, Training Loss:0.0879, Validation Loss: 0.0255\n",
      "Epoch: 36/50, Training Loss:0.0901, Validation Loss: 0.0264\n",
      "Epoch: 37/50, Training Loss:0.0890, Validation Loss: 0.0261\n",
      "Epoch: 38/50, Training Loss:0.0928, Validation Loss: 0.0275\n",
      "Epoch: 39/50, Training Loss:0.0872, Validation Loss: 0.0255\n",
      "Epoch: 40/50, Training Loss:0.0892, Validation Loss: 0.0260\n",
      "Epoch: 41/50, Training Loss:0.0888, Validation Loss: 0.0260\n",
      "Epoch: 42/50, Training Loss:0.0925, Validation Loss: 0.0273\n",
      "Epoch: 43/50, Training Loss:0.0906, Validation Loss: 0.0268\n",
      "Epoch: 44/50, Training Loss:0.0901, Validation Loss: 0.0266\n",
      "Epoch: 45/50, Training Loss:0.0896, Validation Loss: 0.0266\n",
      "Epoch: 46/50, Training Loss:0.0905, Validation Loss: 0.0266\n",
      "Epoch: 47/50, Training Loss:0.0893, Validation Loss: 0.0262\n",
      "Epoch: 48/50, Training Loss:0.0903, Validation Loss: 0.0267\n",
      "Epoch: 49/50, Training Loss:0.0877, Validation Loss: 0.0254\n",
      "Epoch: 50/50, Training Loss:0.0876, Validation Loss: 0.0257\n",
      "LSTM model has been trained.\n",
      "Epoch: 1/50, Training Loss:0.0065, Validation Loss: 0.0274\n",
      "Epoch: 2/50, Training Loss:0.0067, Validation Loss: 0.0274\n",
      "Epoch: 3/50, Training Loss:0.0068, Validation Loss: 0.0272\n",
      "Epoch: 4/50, Training Loss:0.0065, Validation Loss: 0.0278\n",
      "Epoch: 5/50, Training Loss:0.0066, Validation Loss: 0.0280\n",
      "Epoch: 6/50, Training Loss:0.0065, Validation Loss: 0.0276\n",
      "Epoch: 7/50, Training Loss:0.0066, Validation Loss: 0.0274\n",
      "Epoch: 8/50, Training Loss:0.0070, Validation Loss: 0.0280\n",
      "Epoch: 9/50, Training Loss:0.0067, Validation Loss: 0.0279\n",
      "Epoch: 10/50, Training Loss:0.0067, Validation Loss: 0.0275\n",
      "Epoch: 11/50, Training Loss:0.0069, Validation Loss: 0.0282\n",
      "Epoch: 12/50, Training Loss:0.0066, Validation Loss: 0.0278\n",
      "Epoch: 13/50, Training Loss:0.0067, Validation Loss: 0.0276\n",
      "Epoch: 14/50, Training Loss:0.0069, Validation Loss: 0.0280\n",
      "Epoch: 15/50, Training Loss:0.0067, Validation Loss: 0.0275\n",
      "Epoch: 16/50, Training Loss:0.0069, Validation Loss: 0.0285\n",
      "Epoch: 17/50, Training Loss:0.0067, Validation Loss: 0.0280\n",
      "Epoch: 18/50, Training Loss:0.0067, Validation Loss: 0.0278\n",
      "Epoch: 19/50, Training Loss:0.0068, Validation Loss: 0.0279\n",
      "Epoch: 20/50, Training Loss:0.0068, Validation Loss: 0.0281\n",
      "Epoch: 21/50, Training Loss:0.0069, Validation Loss: 0.0282\n",
      "Epoch: 22/50, Training Loss:0.0067, Validation Loss: 0.0278\n",
      "Epoch: 23/50, Training Loss:0.0066, Validation Loss: 0.0274\n",
      "Epoch: 24/50, Training Loss:0.0066, Validation Loss: 0.0271\n",
      "Epoch: 25/50, Training Loss:0.0066, Validation Loss: 0.0276\n",
      "Epoch: 26/50, Training Loss:0.0066, Validation Loss: 0.0276\n",
      "Epoch: 27/50, Training Loss:0.0067, Validation Loss: 0.0276\n",
      "Epoch: 28/50, Training Loss:0.0066, Validation Loss: 0.0273\n",
      "Epoch: 29/50, Training Loss:0.0068, Validation Loss: 0.0281\n",
      "Epoch: 30/50, Training Loss:0.0068, Validation Loss: 0.0278\n",
      "Epoch: 31/50, Training Loss:0.0068, Validation Loss: 0.0284\n",
      "Epoch: 32/50, Training Loss:0.0067, Validation Loss: 0.0277\n",
      "Epoch: 33/50, Training Loss:0.0067, Validation Loss: 0.0275\n",
      "Epoch: 34/50, Training Loss:0.0066, Validation Loss: 0.0274\n",
      "Epoch: 35/50, Training Loss:0.0068, Validation Loss: 0.0277\n",
      "Epoch: 36/50, Training Loss:0.0068, Validation Loss: 0.0277\n",
      "Epoch: 37/50, Training Loss:0.0064, Validation Loss: 0.0270\n",
      "Epoch: 38/50, Training Loss:0.0068, Validation Loss: 0.0279\n",
      "Epoch: 39/50, Training Loss:0.0065, Validation Loss: 0.0269\n",
      "Epoch: 40/50, Training Loss:0.0066, Validation Loss: 0.0276\n",
      "Epoch: 41/50, Training Loss:0.0065, Validation Loss: 0.0273\n",
      "Epoch: 42/50, Training Loss:0.0066, Validation Loss: 0.0272\n",
      "Epoch: 43/50, Training Loss:0.0065, Validation Loss: 0.0270\n",
      "Epoch: 44/50, Training Loss:0.0067, Validation Loss: 0.0278\n",
      "Epoch: 45/50, Training Loss:0.0066, Validation Loss: 0.0275\n",
      "Epoch: 46/50, Training Loss:0.0067, Validation Loss: 0.0277\n",
      "Epoch: 47/50, Training Loss:0.0067, Validation Loss: 0.0282\n",
      "Epoch: 48/50, Training Loss:0.0067, Validation Loss: 0.0277\n",
      "Epoch: 49/50, Training Loss:0.0068, Validation Loss: 0.0280\n",
      "Epoch: 50/50, Training Loss:0.0068, Validation Loss: 0.0280\n",
      "LSTM model has been trained.\n",
      "Epoch: 1/50, Training Loss:0.0189, Validation Loss: 0.0283\n",
      "Epoch: 2/50, Training Loss:0.0198, Validation Loss: 0.0285\n",
      "Epoch: 3/50, Training Loss:0.0184, Validation Loss: 0.0282\n",
      "Epoch: 4/50, Training Loss:0.0189, Validation Loss: 0.0283\n",
      "Epoch: 5/50, Training Loss:0.0183, Validation Loss: 0.0279\n",
      "Epoch: 6/50, Training Loss:0.0194, Validation Loss: 0.0284\n",
      "Epoch: 7/50, Training Loss:0.0194, Validation Loss: 0.0285\n",
      "Epoch: 8/50, Training Loss:0.0190, Validation Loss: 0.0282\n",
      "Epoch: 9/50, Training Loss:0.0201, Validation Loss: 0.0290\n",
      "Epoch: 10/50, Training Loss:0.0184, Validation Loss: 0.0279\n",
      "Epoch: 11/50, Training Loss:0.0187, Validation Loss: 0.0281\n",
      "Epoch: 12/50, Training Loss:0.0192, Validation Loss: 0.0284\n",
      "Epoch: 13/50, Training Loss:0.0188, Validation Loss: 0.0282\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m train, val \u001b[39m=\u001b[39m train_data\u001b[39m.\u001b[39miloc[train_index], train_data\u001b[39m.\u001b[39miloc[val_index]\n\u001b[1;32m     25\u001b[0m model \u001b[39m=\u001b[39m LSTMModel(hidden_size \u001b[39m=\u001b[39m hidden_size, num_layers \u001b[39m=\u001b[39m num_layers, learning_rate\u001b[39m=\u001b[39mlearning_rate, num_epochs\u001b[39m=\u001b[39mnum_epochs )\n\u001b[0;32m---> 26\u001b[0m model\u001b[39m.\u001b[39;49mtrain(train, val, target_column\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mAdj Close\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     28\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mtrained:\n\u001b[1;32m     29\u001b[0m     val_predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(val, target_column\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAdj Close\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Python programs/Time_Series_Pred/models/lstm.py:114\u001b[0m, in \u001b[0;36mLSTMModel.train\u001b[0;34m(self, train_data, val_data, target_column, seq_length)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m    110\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m SequenceModel(\n\u001b[1;32m    111\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_size\n\u001b[1;32m    112\u001b[0m )\n\u001b[0;32m--> 114\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[1;32m    115\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearning_rate)\n\u001b[1;32m    117\u001b[0m best_val_loss \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minf\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:726\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    720\u001b[0m         warn_msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    721\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFor multiprocessing data-loading, this could be caused by not properly configuring the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    722\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mIterableDataset replica at each worker. Please see \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    723\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mhttps://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    724\u001b[0m         )\n\u001b[1;32m    725\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(warn_msg)\n\u001b[0;32m--> 726\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/torch/autograd/profiler.py:769\u001b[0m, in \u001b[0;36mrecord_function.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_scripting():\n\u001b[1;32m    768\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m--> 769\u001b[0m         torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49m_record_function_exit\u001b[39m.\u001b[39;49m_RecordFunction(record)\n\u001b[1;32m    770\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    771\u001b[0m     torch\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39m_record_function_exit(record)\n",
      "File \u001b[0;32m~/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/torch/_ops.py:960\u001b[0m, in \u001b[0;36mTorchBindOpOverload.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_register_as_effectful_op_temporarily():\n\u001b[1;32m    959\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dispatch_in_python(args, kwargs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fallthrough_keys())\n\u001b[0;32m--> 960\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 3. LSTM Hyperparameter Tuning\n",
    "if train_data is not None:\n",
    "    print(\"\\n--- LSTM Hyperparameter Tuning ---\")\n",
    "\n",
    "    param_grid = {\n",
    "    'hidden_size': [20, 50, 100],\n",
    "    'num_layers': [1, 2],\n",
    "    'learning_rate': [0.001, 0.005, 0.01],\n",
    "    'num_epochs' : [50,100]\n",
    "    }\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "\n",
    "    best_score = float('inf')\n",
    "    best_params = None\n",
    "\n",
    "\n",
    "    for hidden_size in param_grid['hidden_size']:\n",
    "        for num_layers in param_grid['num_layers']:\n",
    "            for learning_rate in param_grid['learning_rate']:\n",
    "                for num_epochs in param_grid['num_epochs']:\n",
    "                    scores = []\n",
    "                    for train_index, val_index in tscv.split(train_data):\n",
    "                        train, val = train_data.iloc[train_index], train_data.iloc[val_index]\n",
    "                        model = LSTMModel(hidden_size = hidden_size, num_layers = num_layers, learning_rate=learning_rate, num_epochs=num_epochs )\n",
    "                        model.train(train, val, target_column='Adj Close')\n",
    "\n",
    "                        if model.trained:\n",
    "                            val_predictions = model.predict(val, target_column='Adj Close')\n",
    "                            if val_predictions is not None:\n",
    "                                score = rmse(val['Adj Close'].iloc[10:].values, val_predictions)\n",
    "                                scores.append(score)\n",
    "                            else:\n",
    "                                scores.append(float('inf'))\n",
    "                        else:\n",
    "                            scores.append(float('inf'))\n",
    "                    mean_score = np.mean(scores)\n",
    "                    if mean_score < best_score:\n",
    "                        best_score = mean_score\n",
    "                        best_params = {'hidden_size' : hidden_size, 'num_layers': num_layers, 'learning_rate' : learning_rate, 'num_epochs' : num_epochs}\n",
    "    if best_params is not None:\n",
    "        print(f\"Best LSTM Parameters:  hidden_size={best_params['hidden_size']}, num_layers={best_params['num_layers']}, learning_rate={best_params['learning_rate']}, num_epochs={best_params['num_epochs']} and RMSE : {best_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- XGBoost Hyperparameter Tuning ---\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'estimator' parameter of GridSearchCV must be an object implementing 'fit'. Got <models.xgboost_model.XGBoostModel object at 0x148342df0> instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mif\u001b[39;00m features:\n\u001b[1;32m     18\u001b[0m     grid \u001b[39m=\u001b[39m GridSearchCV(xgb_model, param_grid, cv\u001b[39m=\u001b[39mtscv, scoring\u001b[39m=\u001b[39mrmse_scorer, verbose \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m     grid\u001b[39m.\u001b[39;49mfit(train_data[features], train_data[\u001b[39m'\u001b[39;49m\u001b[39mAdj Close\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     20\u001b[0m     best_params \u001b[39m=\u001b[39m grid\u001b[39m.\u001b[39mbest_params_\n\u001b[1;32m     21\u001b[0m     best_score \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mgrid\u001b[39m.\u001b[39mbest_score_\n",
      "File \u001b[0;32m~/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/base.py:1382\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1377\u001b[0m partial_fit_and_fitted \u001b[39m=\u001b[39m (\n\u001b[1;32m   1378\u001b[0m     fit_method\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpartial_fit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m _is_fitted(estimator)\n\u001b[1;32m   1379\u001b[0m )\n\u001b[1;32m   1381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m global_skip_validation \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[0;32m-> 1382\u001b[0m     estimator\u001b[39m.\u001b[39;49m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[1;32m   1389\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/base.py:436\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_validate_params\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    429\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \n\u001b[1;32m    431\u001b[0m \u001b[39m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[39m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 436\u001b[0m     validate_parameter_constraints(\n\u001b[1;32m    437\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parameter_constraints,\n\u001b[1;32m    438\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_params(deep\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m    439\u001b[0m         caller_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m,\n\u001b[1;32m    440\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Python programs/Time_Series_Pred/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:98\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     constraints_str \u001b[39m=\u001b[39m (\n\u001b[1;32m     94\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(c)\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mconstraints[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]])\u001b[39m}\u001b[39;00m\u001b[39m or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m     )\n\u001b[0;32m---> 98\u001b[0m \u001b[39mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     99\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{\u001b[39;00mparam_name\u001b[39m!r}\u001b[39;00m\u001b[39m parameter of \u001b[39m\u001b[39m{\u001b[39;00mcaller_name\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints_str\u001b[39m}\u001b[39;00m\u001b[39m. Got \u001b[39m\u001b[39m{\u001b[39;00mparam_val\u001b[39m!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'estimator' parameter of GridSearchCV must be an object implementing 'fit'. Got <models.xgboost_model.XGBoostModel object at 0x148342df0> instead."
     ]
    }
   ],
   "source": [
    "# 4. XGBoost Hyperparameter Tuning\n",
    "if train_data is not None:\n",
    "    print(\"\\n--- XGBoost Hyperparameter Tuning ---\")\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [3, 5],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.7, 1.0]\n",
    "    }\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    xgb_model = XGBoostModel()\n",
    "    features = [\n",
    "        col\n",
    "        for col in train_data.columns\n",
    "        if col != \"Adj Close\" and col != \"Date\" and train_data[col].dtype in ['int64', 'float64']\n",
    "    ]\n",
    "    if features:\n",
    "        grid = GridSearchCV(xgb_model, param_grid, cv=tscv, scoring=rmse_scorer, verbose = 0)\n",
    "        grid.fit(train_data[features], train_data['Adj Close'])\n",
    "        best_params = grid.best_params_\n",
    "        best_score = -grid.best_score_\n",
    "        print(f\"Best XGBoost Parameters: {best_params} and RMSE: {best_score:.2f}\")\n",
    "    else:\n",
    "        print(\"No numerical features available for XGBoost Tuning\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f9e42c9691f8fec9a9bc08c7e23b35930eb26ad2af69833e566a8b563b2c498"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
